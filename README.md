# Titanic: Machine Learning from Disaster on Kaggle

### Objective
***
Using XGBoost to predict passengers of Titanic "Survived" or not.

### Process
***
Explore the data first. Then try to extract feature as much as possible. Select the important features to train XGBoost model. The result is uploaded to score on Kaggle. It's 0.77990. <br>

Link is here: https://github.com/TrinVeerasiri/Titanic-Machine-Learning-from-Disaster-on-Kaggle/blob/master/titanic_trin.ipynb
